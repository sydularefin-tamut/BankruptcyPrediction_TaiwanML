{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7812/1971618734.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLeastGaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussianTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresultVisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The prediction result of LS classification with gaussian basis is:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7812/1971618734.py\u001b[0m in \u001b[0;36mgaussianTrain\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mX_XT_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_x_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_x_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_XT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_XT_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgaussian_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7812/1971618734.py\u001b[0m in \u001b[0;36mgaussian_predict\u001b[1;34m(self, train_test)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mtarget_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'class 1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class 2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobaLst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mkahs\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m     if y_type == \"multiclass\" or (\n",
      "\u001b[1;32mc:\\Users\\mkahs\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mkahs\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class LeastGaussian():\n",
    "    def __init__(self):\n",
    "        self.recordDict = {\"class1 F1\": [], \"class2 F1\": [], \"Accuracy\": [], \"AUC\": []}\n",
    "        self.readData()\n",
    "        self.dataSqrt(1/4)\n",
    "        self.outsideAdj()\n",
    "        self.kClusteringMean(20)\n",
    "        self.normalRandomMean(80, 119020084)\n",
    "        self.probaLst = []\n",
    "\n",
    "    def readData(self):\n",
    "        train_org = pd.read_csv(\"./train.csv\")\n",
    "        self.train_x = train_org.drop(['target'], axis = 1)\n",
    "        self.origin_y = train_org[\"target\"]\n",
    "        self.train_y = self.classOneHot(train_org[\"target\"])\n",
    "        test_org = pd.read_csv(\"./test.csv\") \n",
    "        self.test_x = test_org.drop(['target'], axis = 1)\n",
    "        self.test_y = test_org[\"target\"]\n",
    "\n",
    "    def classOneHot(self, label_arr):\n",
    "        \"\"\"\n",
    "        Transform label array into matrix. The size is n*k, k is the number of classes\n",
    "        This is one-hot transformation\n",
    "        \"\"\"\n",
    "        n_class = np.unique(label_arr).size\n",
    "        y_matrix = np.zeros((label_arr.shape[0],n_class))\n",
    "        y_matrix[label_arr==0,0] = 1\n",
    "        y_matrix[label_arr==1,1] = 1\n",
    "        return y_matrix.T\n",
    "\n",
    "    def dataSqrt(self, power):\n",
    "        \"\"\"\n",
    "        First transform all the data into positive\n",
    "        Then take square root\n",
    "        Lastly, transform the negative data into negative.\n",
    "        \"\"\"\n",
    "        train_x_abs = np.power(np.abs(self.train_x), power)\n",
    "        train_x_abs[self.train_x<0] = -train_x_abs[self.train_x<0]\n",
    "        self.train_x = train_x_abs\n",
    "        test_x_abs = np.power(np.abs(self.test_x), power)\n",
    "        test_x_abs[self.test_x<0] = -test_x_abs[self.test_x<0]\n",
    "        self.test_x = test_x_abs\n",
    "\n",
    "\n",
    "    def outsideAdj(self):\n",
    "        mu = self.train_x.mean()\n",
    "        sigma = np.sqrt(self.train_x.var())\n",
    "        upper_bound = mu + 1 * sigma\n",
    "        lower_bound = mu - 1 * sigma\n",
    "        for attr in lower_bound.index:\n",
    "            self.train_x[attr][self.train_x[attr] > upper_bound[attr]] = upper_bound[attr]\n",
    "            self.test_x[attr][self.test_x[attr] > upper_bound[attr]] = upper_bound[attr]\n",
    "            self.train_x[attr][self.train_x[attr] < lower_bound[attr]] = lower_bound[attr]\n",
    "            self.test_x[attr][self.test_x[attr] < lower_bound[attr]] = lower_bound[attr]\n",
    "        self.train_x = (self.train_x - self.train_x.min()) / (self.train_x.max() - self.train_x.min())*10\n",
    "        self.test_x = (self.test_x - self.test_x.min()) / (self.test_x.max() - self.test_x.min())*10\n",
    "\n",
    "    def kClusteringMean(self, n):\n",
    "        \"\"\"\n",
    "        Use k-clustering method to find 20 mean values\n",
    "        \"\"\"\n",
    "        train_adj = self.train_x.copy()\n",
    "        train_adj[\"cluster\"] = KMeans(n_clusters=n, max_iter=10000, random_state=119020).fit_predict(self.train_x)\n",
    "        train_adj_mean = train_adj.groupby(\"cluster\").mean()\n",
    "        self.k_cluster_mean = train_adj_mean\n",
    "\n",
    "    def normalRandomMean(self, n, seed):\n",
    "        mean_var_lst = list(zip(self.train_x.mean(), np.sqrt(self.train_x.var())))\n",
    "        zeros = np.zeros([n, len(mean_var_lst)])\n",
    "        for attr in range(len(mean_var_lst)):\n",
    "            np.random.seed(seed)\n",
    "            zeros[:,attr] = np.random.normal(mean_var_lst[attr][0], mean_var_lst[attr][1],n)\n",
    "        zeros = pd.DataFrame(zeros, columns = self.k_cluster_mean.columns)\n",
    "        self.mean_generate = pd.concat([pd.DataFrame(zeros), self.k_cluster_mean])\n",
    "        \n",
    "\n",
    "    def gaussianTransform(self, row):\n",
    "        gaussian_x_train = np.exp(- (self.train_x - self.mean_generate.iloc[row,])**2 / 2 * self.train_x.var())\n",
    "        guassian_x_test = np.exp(- (self.test_x - self.mean_generate.iloc[row,])**2 / 2 * self.test_x.var())\n",
    "        gaussian_x_train[\"constant\"] = 1\n",
    "        guassian_x_test[\"constant\"] = 1\n",
    "        self.gaussian_x_train = np.array(gaussian_x_train).T\n",
    "        self.gaussian_x_test = np.array(guassian_x_test).T\n",
    "    \n",
    "    def gaussianTrain(self, row):\n",
    "        self.gaussianTransform(row)\n",
    "        T_XT = np.dot(self.train_y, self.gaussian_x_train.T)\n",
    "        X_XT_inv = np.linalg.pinv(np.dot(self.gaussian_x_train, self.gaussian_x_train.T))\n",
    "        self.parameters = np.dot(T_XT, X_XT_inv)\n",
    "        self.gaussian_predict()\n",
    "\n",
    "    def gaussian_predict(self, train_test=False):\n",
    "        df = pd.DataFrame(np.dot(self.parameters, self.gaussian_x_test)).T\n",
    "        self.mydf = df\n",
    "        df[\"predict\"] = 0\n",
    "        df.loc[df[1]>df[0], \"predict\"] = 1\n",
    "        target_names = ['class 1', 'class 2']\n",
    "        self.auc_score = roc_auc_score(np.array(self.test_y), df[1])\n",
    "        self.probaLst.append(df[1])\n",
    "        result = classification_report(np.array(self.test_y), df['predict'], target_names=target_names)\n",
    "        self.result = result\n",
    "        self.recordDict[\"class1 F1\"].append(float(self.result.split(\"\\n\")[2].split()[4]))\n",
    "        self.recordDict[\"class2 F1\"].append(float(self.result.split(\"\\n\")[3].split()[4]))\n",
    "        self.recordDict[\"Accuracy\"].append(float(self.result.split(\"\\n\")[5].split()[1]))\n",
    "        self.recordDict[\"AUC\"].append(self.auc_score)\n",
    "    \n",
    "    def resultVisualize(self):\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.style.use(\"ggplot\")   \n",
    "        plt.plot(self.recordDict[\"class1 F1\"], linestyle='--', color=\"grey\",lw=2)\n",
    "        plt.plot(self.recordDict[\"class2 F1\"], linestyle='--', color=\"darkgrey\",lw=2)\n",
    "        plt.plot(self.recordDict[\"Accuracy\"], linestyle='-', color=\"blue\", lw=3)\n",
    "        plt.plot(self.recordDict[\"AUC\"], linestyle='-', color=\"red\", lw=3)\n",
    "        plt.axvline(20, ls=\"--\", lw=3)\n",
    "        plt.legend(self.recordDict.keys(), fontsize=14, loc=1)\n",
    "        plt.text(2, 0.2, \"K-clustering\", color = \"red\", font = {'family': 'normal', 'weight': 'bold', 'size': 18})\n",
    "        plt.text(40, 0.2, \"Random Generate\", color = \"red\", font = {'family': 'normal', 'weight': 'bold', 'size': 18})\n",
    "        plt.xlabel(\"Times\", font = {'family': 'normal', 'weight': 'bold', 'size': 18})\n",
    "        plt.ylabel(\"Predict Score\", font = {'family': 'normal', 'weight': 'bold', 'size': 18})\n",
    "        plt.xticks(font = {'family': 'normal', 'weight': 'normal', 'size': 14})\n",
    "        plt.yticks(font = {'family': 'normal', 'weight': 'normal', 'size': 14})\n",
    "        plt.title(\"LS Classification with Gaussian Basis Functions\\n(Best Accuracy={}, Best AUC={})\".format(np.array(self.recordDict[\"Accuracy\"]).max(),\\\n",
    "            np.round(np.array(self.recordDict[\"AUC\"]).max(), 2)),\\\n",
    "             font = {'family': 'normal', 'weight': 'bold', 'size': 18})\n",
    "    \n",
    "    def resultReport(self):\n",
    "        acc_array = np.array(self.recordDict[\"Accuracy\"])\n",
    "        best_row = np.where(acc_array == acc_array.max())[0][0]\n",
    "        self.gaussianTrain(best_row)\n",
    "        print(self.result)\n",
    "        print(\"AUC: \", np.round(self.auc_score, 2))\n",
    "\n",
    "    def draw_roc(self):\n",
    "        score = self.probaLst[-1]\n",
    "        score = (score - score.min()) / (score.max() - score.min())\n",
    "        auc = roc_auc_score(self.test_y, score)\n",
    "        fpr, tpr, _ = roc_curve(self.test_y, score)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                label='ROC curve (area = %0.2f)' % auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC for testing set')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        self.gaussian_x_test = self.gaussian_x_train\n",
    "        self.test_y = self.origin_y\n",
    "        self.gaussian_predict()\n",
    "        print(\"*****Result for Training Data*****\")\n",
    "        print(self.result)\n",
    "        print(\"AUC: \", np.round(self.auc_score, 2))\n",
    "        score = self.probaLst[-1]\n",
    "        score = (score - score.min()) / (score.max() - score.min())\n",
    "        auc = roc_auc_score(self.origin_y, score)\n",
    "        fpr, tpr, _ = roc_curve(self.origin_y, score)\n",
    "        plt.subplot(122)\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                label='ROC curve (area = %0.2f)' % auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC for training set')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = LeastGaussian()\n",
    "    for i in range(100):\n",
    "        p.gaussianTrain(i)\n",
    "    p.resultVisualize()\n",
    "    print(\"The prediction result of LS classification with gaussian basis is:\")\n",
    "    p.resultReport()\n",
    "    p.draw_roc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RTX2080",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
